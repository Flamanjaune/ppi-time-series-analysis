{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5hGUr2QmJ5n"
      },
      "source": [
        "# Code Article"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLnae5kRvaxo"
      },
      "source": [
        "## Packages ARIMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13GPPSYicDVS"
      },
      "outputs": [],
      "source": [
        "!pip install -q altair==5.2.0 \\\n",
        "                 matplotlib==3.8.2 \\\n",
        "                 numpy==2.0.0 \\\n",
        "                 pandas==2.2.2 \\\n",
        "                 pmdarima>=2.0.4 \\\n",
        "                 Rbeast==0.1.23 \\\n",
        "                 scipy>=1.14.0 \\\n",
        "                 seaborn==0.13.2 \\\n",
        "                 statsmodels==0.14.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hcOIsGmM8D9_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjaACnul6jck"
      },
      "outputs": [],
      "source": [
        "!pip install pmdarima>=2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvenNktK6o5I"
      },
      "outputs": [],
      "source": [
        "import pmdarima as pm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szAFNEVGvaC7"
      },
      "outputs": [],
      "source": [
        "# Calculs scientifiques\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Visualisation\n",
        "import altair as alt\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import YearLocator, DateFormatter\n",
        "import seaborn as sns\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# Modèles statistiques et séries temporelles\n",
        "#import pmdarima as pm\n",
        "#import Rbeast as rb\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from statsmodels.tsa.stattools import adfuller"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OEQKcZrmitn"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CyGLGO_oOKO"
      },
      "source": [
        "### Upload File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNTtRqh5mT1y"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3WJ63s-m2ue"
      },
      "source": [
        "### Load Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGjh7DBpmx9t"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PPI_data_final.csv\")\n",
        "df['Date'] = pd.date_range(start='2009-02-01', periods=len(df), freq='M')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KJMP3ixHOnl"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZDiiLq3yB01"
      },
      "outputs": [],
      "source": [
        "# Comparison by molecules\n",
        "plt.style.use('default')\n",
        "fig, ax = plt.subplots(figsize=(12,7))\n",
        "\n",
        "plt.plot(df['Date'].values, df['Y_PANTOPRAZOLE'].values, label='Pantoprazole')\n",
        "plt.plot(df['Date'].values, df['Y_ESOMEPRAZOLE'].values, label='Esomeprazole')\n",
        "plt.plot(df['Date'].values, df['Y_OMEPRAZOLE'].values, label='Omeprazole')\n",
        "plt.plot(df['Date'].values, df['Y_LANSOPRAZOLE'].values, label='Lansoprazole')\n",
        "plt.plot(df['Date'].values, df['Y_RABEPRAZOLE'].values, label='Rabeprazole')\n",
        "plt.plot(df['Date'].values, df['Y_DEXLANSOPRAZOLE'].values, label='Dexlansoprazole')\n",
        "\n",
        "plt.title('Comparison of oral PPI DDD by molecules')\n",
        "plt.ylabel('Oral PPI DDD per 100.000 habitants')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INBWkU2PCcQv"
      },
      "outputs": [],
      "source": [
        "# Intravenous PPI sales\n",
        "plt.style.use('default')\n",
        "fig, ax = plt.subplots(figsize=(12,7))\n",
        "\n",
        "# Plot bounce rate data\n",
        "ax.scatter(df['Date'], df['Y_PPI_IV'], facecolors='k', edgecolors='k', label='IV PPI data', linewidths=1,s=10)\n",
        "\n",
        "plt.title('Intravenous PPI sales rate in Switzerland over time')\n",
        "plt.ylabel(\"Intravenous PPI sales rate per 100'000 habitants\");\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6YtK_itzfXh"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdqvzILtCiKi"
      },
      "outputs": [],
      "source": [
        "# convert the Purchase Date to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "# add a column for Year\n",
        "df['Year'] = df['Date'].dt.year\n",
        "# print the dataframe\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UClhEoNXz7mi"
      },
      "source": [
        "### Adfuller Test for Stationarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_I_53Qj0AzC"
      },
      "source": [
        "This test is used to decide whether the data are stationary or not.\n",
        "- If the data are stationary, we set d = 0.\n",
        "- If the data are not stationary, we need to analyze the model in greater depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzBqlnhq0GQI"
      },
      "outputs": [],
      "source": [
        "def adf_test(dataset):\n",
        "    dftest = adfuller(dataset, autolag = 'AIC')\n",
        "    print(\"1. ADF : \",dftest[0])\n",
        "    print(\"2. P-Value : \", round(dftest[1],6))\n",
        "    print(\"3. Num Of Lags : \", dftest[2])\n",
        "    print(\"4. Num Of Observations Used For ADF Regression and Critical Values Calculation :\", dftest[3])\n",
        "    print(\"5. Critical Values :\")\n",
        "    for key, val in dftest[4].items():\n",
        "       print(\"\\t\",key, \": \", val)\n",
        "    if dftest[0] < dftest[4][\"5%\"]:\n",
        "        print (\"Reject Ho - Time Series is Stationary\")\n",
        "    else:\n",
        "        print (\"Failed to Reject Ho - Time Series is Non-Stationary\")\n",
        "\n",
        "adf_test(df.Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN7OqHFU1gbv"
      },
      "source": [
        "### Seasonality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg-vis4z2xTn"
      },
      "source": [
        "Looking at the ACF chart, we can see that the autocorrelation trend is decreasing, with peaks every 6 months.\n",
        "\n",
        "We'll therefore choose 6 or 12 months as the seasonality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POtNXmN21e7o"
      },
      "outputs": [],
      "source": [
        "lag_acf = 50\n",
        "lag_pacf = 50\n",
        "\n",
        "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 6))\n",
        "plot_acf(df.Y,lags=lag_acf, ax=ax[0],alpha=.05);\n",
        "plot_pacf(df.Y,lags=lag_pacf, ax=ax[1],alpha=.05);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1FVJtzUyITq"
      },
      "source": [
        "We can confirme this hypothesis by de-trending the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xzfE2UkyS9n"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PPI_data_final.csv\")\n",
        "\n",
        "df_trend = df - df.rolling(15).mean()\n",
        "\n",
        "# Drop the NaN values\n",
        "df_trend = df_trend.dropna()\n",
        "df_trend[df_trend < 0] = 15000\n",
        "# Create figure and subplots\n",
        "lag_acf = 36\n",
        "lag_pacf = 36\n",
        "\n",
        "f, ax = plt.subplots(nrows=2, ncols=1, figsize=(10, 6))\n",
        "plot_acf(df_trend.Y,lags=lag_acf, ax=ax[0],alpha=.05);\n",
        "plot_pacf(df_trend.Y,lags=lag_pacf, ax=ax[1],alpha=.05);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e3XekLr3wMl"
      },
      "source": [
        "According to the de-trend acf and pacf, we set m=12 for the seasonality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9HnjVdf3B1w"
      },
      "source": [
        "### Auto ARIMA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5CncWOz32bA"
      },
      "source": [
        "It is now possible to use the auto-arima function to define the missing terms (p,q,P,Q,D)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQjXs4Ky3W10"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PPI_data_final.csv\")\n",
        "df['Date'] = pd.date_range(start='2009-02-01', periods=len(df), freq='M')\n",
        "# fit stepwise auto-ARIMA\n",
        "# aic\n",
        "stepwise_fit_aic = pm.auto_arima(df.Y, start_p=1, start_q=1, max_p=5, max_q=5,d=0,\n",
        "                             start_P=1, D=None, start_Q=1, max_P=5, max_D=1, max_Q=5, max_order=None, seasonal=True,m=12,\n",
        "                             maxiter=20, trace=True,alpha=0.05, information_criterion = \"aic\",\n",
        "                             return_valid_fits = True,\n",
        "                             error_action='ignore',  # don't want to know if an order does not work\n",
        "                             suppress_warnings=True,  # don't want convergence warnings\n",
        "                             stepwise=True);  # set to stepwise\n",
        "# bic\n",
        "stepwise_fit_bic = pm.auto_arima(df.Y, start_p=1, start_q=1, max_p=5, max_q=5,d=0,\n",
        "                             start_P=1, D=None, start_Q=1, max_P=5, max_D=1, max_Q=5, max_order=None, seasonal=True,m=12,\n",
        "                             maxiter=20, trace=True,alpha=0.05, information_criterion = \"bic\",\n",
        "                             return_valid_fits = True,\n",
        "                             error_action='ignore',  # don't want to know if an order does not work\n",
        "                             suppress_warnings=True,  # don't want convergence warnings\n",
        "                             stepwise=True);  # set to stepwise\n",
        "# hqic\n",
        "stepwise_fit_hqic = pm.auto_arima(df.Y, start_p=1, start_q=1, max_p=5, max_q=5,d=0,\n",
        "                             start_P=1, D=None, start_Q=1, max_P=5, max_D=1, max_Q=5, max_order=None, seasonal=True,m=12,\n",
        "                             maxiter=20, trace=True,alpha=0.05, information_criterion = \"hqic\",\n",
        "                             return_valid_fits = True,\n",
        "                             error_action='ignore',  # don't want to know if an order does not work\n",
        "                             suppress_warnings=True,  # don't want convergence warnings\n",
        "                             stepwise=True);  # set to stepwise\n",
        "# oob\n",
        "stepwise_fit_oob = pm.auto_arima(df.Y, start_p=1, start_q=1, max_p=5, max_q=5,d=0,\n",
        "                             start_P=1, D=None, start_Q=1, max_P=5, max_D=1, max_Q=5, max_order=None, seasonal=True,m=12,\n",
        "                             maxiter=20, trace=True,alpha=0.05, information_criterion = \"oob\", out_of_sample_size=12,  # Specify non-zero holdout\n",
        "                             return_valid_fits = True,\n",
        "                             error_action='ignore',  # don't want to know if an order does not work\n",
        "                             suppress_warnings=True,  # don't want convergence warnings\n",
        "                             stepwise=True);  # set to stepwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orKBbrCu0yQE"
      },
      "source": [
        "Create a table with the best parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pc3H6F6DZ8BQ"
      },
      "outputs": [],
      "source": [
        "d = {'aic': stepwise_fit_aic[0:5], 'bic': stepwise_fit_bic[0:5], 'hqic': stepwise_fit_hqic[0:5], 'oob': stepwise_fit_oob[0:5] }\n",
        "df = pd.DataFrame(data=d)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVLGUBwxE8VW"
      },
      "source": [
        "Now we can perform ljungbox and normal test for each set of parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL3EZDhvBmz_"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PPI_data_final.csv\")\n",
        "df['Date'] = pd.date_range(start='2009-02-01', periods=len(df), freq='M')\n",
        "\n",
        "aic_ljungbox = []\n",
        "aic_normal = []\n",
        "bic_ljungbox = []\n",
        "bic_normal = []\n",
        "hqic_ljungbox = []\n",
        "hqic_normal = []\n",
        "oob_ljungbox = []\n",
        "oob_normal = []\n",
        "\n",
        "#aic\n",
        "for i in range(5):\n",
        "  mod = stepwise_fit_aic[i]\n",
        "  p,d,q = mod.get_params(deep=False)[\"order\"]\n",
        "  P,D,Q,s = mod.get_params(deep=False)['seasonal_order']\n",
        "  arima_results = ARIMA(df[\"Y\"], df[[\"T\",\"D\",\"P\"]], order=(p,d,q),seasonal_order=(P,D,Q,s)).fit()\n",
        "  ljungbox = sm.stats.acorr_ljungbox(arima_results.resid, lags=[24], return_df=True)\n",
        "  normal = stats.normaltest(arima_results.resid)\n",
        "  aic_ljungbox.append(ljungbox[\"lb_pvalue\"][24])\n",
        "  aic_normal.append(normal.pvalue)\n",
        "\n",
        "#bic\n",
        "for i in range(5):\n",
        "  mod = stepwise_fit_bic[i]\n",
        "  p,d,q = mod.get_params(deep=False)[\"order\"]\n",
        "  P,D,Q,s = mod.get_params(deep=False)['seasonal_order']\n",
        "  arima_results = ARIMA(df[\"Y\"], df[[\"T\",\"D\",\"P\"]], order=(p,d,q),seasonal_order=(P,D,Q,s)).fit()\n",
        "  ljungbox = sm.stats.acorr_ljungbox(arima_results.resid, lags=[24], return_df=True)\n",
        "  normal = stats.normaltest(arima_results.resid)\n",
        "  bic_ljungbox.append(ljungbox[\"lb_pvalue\"][24])\n",
        "  bic_normal.append(normal.pvalue)\n",
        "\n",
        "#hqic\n",
        "for i in range(5):\n",
        "  mod = stepwise_fit_hqic[i]\n",
        "  p,d,q = mod.get_params(deep=False)[\"order\"]\n",
        "  P,D,Q,s = mod.get_params(deep=False)['seasonal_order']\n",
        "  arima_results = ARIMA(df[\"Y\"], df[[\"T\",\"D\",\"P\"]], order=(p,d,q),seasonal_order=(P,D,Q,s)).fit()\n",
        "  ljungbox = sm.stats.acorr_ljungbox(arima_results.resid, lags=[24], return_df=True)\n",
        "  normal = stats.normaltest(arima_results.resid)\n",
        "  hqic_ljungbox.append(ljungbox[\"lb_pvalue\"][24])\n",
        "  hqic_normal.append(normal.pvalue)\n",
        "\n",
        "#oob\n",
        "for i in range(5):\n",
        "  mod = stepwise_fit_oob[i]\n",
        "  p,d,q = mod.get_params(deep=False)[\"order\"]\n",
        "  P,D,Q,s = mod.get_params(deep=False)['seasonal_order']\n",
        "  arima_results = ARIMA(df[\"Y\"], df[[\"T\",\"D\",\"P\"]], order=(p,d,q),seasonal_order=(P,D,Q,s)).fit()\n",
        "  ljungbox = sm.stats.acorr_ljungbox(arima_results.resid, lags=[24], return_df=True)\n",
        "  normal = stats.normaltest(arima_results.resid)\n",
        "  oob_ljungbox.append(ljungbox[\"lb_pvalue\"][24])\n",
        "  oob_normal.append(normal.pvalue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muXSiVMOGp6L"
      },
      "outputs": [],
      "source": [
        "d = {'aic_ljungbox': aic_ljungbox, 'aic_normal': aic_normal, 'bic_ljungbox': bic_ljungbox, 'bic_normal': bic_normal,\n",
        "     'hqic_ljungbox': hqic_ljungbox, 'hqic_normal': hqic_normal, 'oob_ljungbox': oob_ljungbox, 'oob_normal': oob_normal}\n",
        "df_test = pd.DataFrame(data=d)\n",
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB9nCdslM9PZ"
      },
      "source": [
        "From the table, we can deduce that the best parameters are the 1st from the bic measure (the ones on the list to accept $H_0$ for both the residuals and the normality)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfSxl2kFNLi7"
      },
      "outputs": [],
      "source": [
        "stepwise_fit_bic[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRi0Xu6N7Szp"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BjPus1N7V9j"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PPI_data_final.csv\")\n",
        "df['Date'] = pd.date_range(start='2009-02-01', periods=len(df), freq='ME')\n",
        "p = 3\n",
        "d = 0\n",
        "q = 0\n",
        "P = 1\n",
        "D = 0\n",
        "Q = 0\n",
        "s = 12\n",
        "arima_results = ARIMA(df[\"Y\"], df[[\"T\",\"D\",\"P\"]], order=(p,d,q),seasonal_order=(P,D,Q,s)).fit()\n",
        "print(arima_results.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7lRzpFs7bSk"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwwmJe9u4YH6"
      },
      "outputs": [],
      "source": [
        "start = 66\n",
        "end = 132\n",
        "df['Date'] = pd.date_range(start='2009-02-01', periods=len(df), freq='M')\n",
        "intervention_date = df['Date'][start-1]\n",
        "\n",
        "predictions = arima_results.get_prediction(0,end-1)\n",
        "summary = predictions.summary_frame(alpha=0.05)\n",
        "\n",
        "arima_cf = ARIMA(df[\"Y\"][0:start], df[\"T\"][0:start], order=(p,d,q),seasonal_order=(P,D,Q,s)).fit()\n",
        "\n",
        "# Model predictions means\n",
        "y_pred = predictions.predicted_mean\n",
        "\n",
        "# Counterfactual mean and 95% confidence interval\n",
        "y_cf = arima_cf.get_forecast(end-start, exog=df[\"T\"][start:end]).summary_frame(alpha=0.05)\n",
        "\n",
        "# Plot section\n",
        "plt.style.use('default')\n",
        "fig, ax = plt.subplots(figsize=(12,7))\n",
        "ax.set_ylim([150000, 480000])\n",
        "\n",
        "# Plot bounce rate data\n",
        "ax.scatter(df[\"Date\"], df[\"Y\"], facecolors='k', edgecolors='k', label=\"PPI data\", linewidths=1,s=10)\n",
        "\n",
        "# Plot model mean bounce prediction\n",
        "ax.plot(df[\"Date\"][:start], y_pred[0:start], 'C0-', label=\"Model prediction\")\n",
        "ax.plot(df[\"Date\"][start-1:end], y_pred[start-1:], 'C0-')\n",
        "\n",
        "# Plot counterfactual mean bounce rate with 95% confidence interval\n",
        "ax.plot(df[\"Date\"][start:], y_cf[\"mean\"], 'C1-', label=\"Counterfactual\")\n",
        "ax.fill_between(df[\"Date\"][start:], y_cf['mean_ci_lower'], y_cf['mean_ci_upper'], color='C1', alpha=0.2, label=\"Counterfactual 95% CI\");\n",
        "\n",
        "\n",
        "# Plot line marking intervention moment\n",
        "ax.axvline(x = intervention_date, color = 'C3', linestyle='--', label = 'Intervention (May 2014)')\n",
        "ax.legend(loc='upper left')\n",
        "plt.title('Oral PPI DDD in Switzerland over time')\n",
        "#plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Oral PPI DDD per 100'000 habitants\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNHhWqmO4lVM"
      },
      "source": [
        "It is possible to check the quality of the parameters set for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hgX4gfV5ji7"
      },
      "source": [
        "Ljung-Box test to check if autocorrelation exists in a time series:\n",
        "- H0: The residuals are independently distributed.\n",
        "\n",
        "- H1: The residuals are not independently distributed; they exhibit serial correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-whr4wau5dFE"
      },
      "outputs": [],
      "source": [
        "sm.stats.acorr_ljungbox(arima_results.resid, lags=[24], return_df=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO3F-TIr6Mee"
      },
      "source": [
        "Here lb_value > 0.05 so we can conclude that the residuals are independently distributed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5CVGEqtI13T"
      },
      "source": [
        "And we can check if the residuals are normally distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJKVWx3F6nrB"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "stats.normaltest(arima_results.resid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DheXVJSzgRA"
      },
      "outputs": [],
      "source": [
        "arima_results.plot_diagnostics(figsize=(14,10));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr0UXyWyzySa"
      },
      "source": [
        "Here's what we can deduce:\n",
        "- No correlation in residuals (top-left plot)\n",
        "- The residuals follows a normal distribution (top-right and bottom-left plot)\n",
        "- Low correlations in residuals (bottom-right plot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0EfngkY73EM"
      },
      "source": [
        "## Rbeast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IdkQCjLBBU_"
      },
      "outputs": [],
      "source": [
        "pip install Rbeast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqTwnyf_BOY2"
      },
      "outputs": [],
      "source": [
        "!python -m pip uninstall -y numpy\n",
        "!python -m pip install --no-cache-dir --force-reinstall \"numpy==1.26.4\"\n",
        "!python -c \"import numpy as np; print(np.__version__)\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWgH_MuwBXKe"
      },
      "outputs": [],
      "source": [
        "import Rbeast as rb\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPEQ3eULr25d"
      },
      "source": [
        "### BMA Analysis for PPI pills\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTo7GSxs8cp1"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PPI_data_final.csv\")\n",
        "df['Date'] = pd.date_range(start='2009-02-01', periods=len(df), freq='ME')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HljmKk78eYE"
      },
      "outputs": [],
      "source": [
        "data, date = df.Y, df.Date\n",
        "start_month=2009+1/12\n",
        "o = rb.beast(data, start=start_month, deltat=1/12, period = 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j12FlLGe9GBS"
      },
      "outputs": [],
      "source": [
        "# Plot section\n",
        "rb.plot(o);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04GRvrVxdg_9"
      },
      "outputs": [],
      "source": [
        "rb.print(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWY8LJHABUtZ"
      },
      "outputs": [],
      "source": [
        "print(dir(o.trend.cpOccPr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OctyqDwqCfIL"
      },
      "outputs": [],
      "source": [
        "# Assuming o.time is the time array that aligns with cpOccPr\n",
        "cp_time = o.time\n",
        "cp_occ_pr = o.trend.cpOccPr\n",
        "df = pd.DataFrame({\n",
        "    'cp_time': cp_time,\n",
        "    'cp_occ_pr': cp_occ_pr,\n",
        "    'Date': pd.date_range(start='2009-02-01', periods=len(cp_time), freq='ME')\n",
        "})\n",
        "print(df.head(128))\n",
        "\n",
        "# Define the interval start and end\n",
        "interval_start = 2014+4/12\n",
        "interval_end = 2016+4/12\n",
        "intervention_date = df['Date'][64]\n",
        "\n",
        "# Filter the DataFrame for the desired interval\n",
        "filtered_df = df[(df['cp_time'] >= interval_start) & (df['cp_time'] < interval_end)]\n",
        "\n",
        "# Sum the probabilities for the filtered interval\n",
        "sum_probs = filtered_df['cp_occ_pr'].sum()\n",
        "print(\"Sum of changepoint probabilities over the interval:\", sum_probs)\n",
        "print(\"We have a\", sum_probs * 100, \"% chance that the change occurred between May-2014 and May-2016\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Date'], df['cp_occ_pr'], label='Changepoint Occurrence Probability')\n",
        "plt.fill_between(filtered_df['Date'], filtered_df['cp_occ_pr'], color='skyblue', alpha=0.4, label=f'AUC from 05/2014 to 05/2016: {sum_probs:.2f}')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Changepoint Occurrence Probability For Oral PPI DDD Over Time')\n",
        "plt.axvline(x=intervention_date, color='C3', linestyle='--', label='Intervention (May 2014)')\n",
        "plt.legend()\n",
        "plt.ylim(-0.005, 0.107)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMtkYg1nC1zT"
      },
      "outputs": [],
      "source": [
        "# Define the interval start and end\n",
        "interval_start = 2014+4/12\n",
        "interval_end = 2016+4/12\n",
        "# o.time is a NumPy array with time points\n",
        "# o.trend.cpOccPr is a NumPy array with corresponding probabilities\n",
        "\n",
        "# Find indices where time falls within the interval\n",
        "interval_indices = np.where((o.time >= interval_start) & (o.time < interval_end))\n",
        "\n",
        "# Extract the probabilities for these indices\n",
        "interval_probs = o.trend.cpOccPr[interval_indices]\n",
        "\n",
        "# Sum the probabilities\n",
        "sum_probs = np.sum(interval_probs)\n",
        "\n",
        "print(\"Sum of changepoint probabilities over the interval:\", sum_probs)\n",
        "print(\"We have a\", sum_probs*100, \"% chance that the change occured between May-2014 and May-2016\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qdtsf9UtXXm"
      },
      "source": [
        "### BMA Analysis for PPI Infusion bottles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f60pZl4frq--"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"PPI_data_final.csv\")\n",
        "df['Date'] = pd.date_range(start='2009-02-01', periods=len(df), freq='ME')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utb7nvT4qcx8"
      },
      "outputs": [],
      "source": [
        "data, date = df.Y_PPI_IV, df.Date\n",
        "start_month = 2009+1/12\n",
        "o = rb.beast(data, start=start_month, deltat=1/12, period = 1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AAjMz1Vqcx9"
      },
      "outputs": [],
      "source": [
        "# Plot section\n",
        "rb.plot(o);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjLzEnoJqcx-"
      },
      "outputs": [],
      "source": [
        "rb.print(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ASKd8r1qcx-"
      },
      "outputs": [],
      "source": [
        "print(dir(o.trend.cpOccPr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FV3kyJfqcx_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Assuming o.time is the time array that aligns with cpOccPr\n",
        "cp_time = o.time\n",
        "cp_occ_pr = o.trend.cpOccPr\n",
        "df = pd.DataFrame({\n",
        "    'cp_time': cp_time,\n",
        "    'cp_occ_pr': cp_occ_pr,\n",
        "    'Date': pd.date_range(start='2009-02-01', periods=len(cp_time), freq='ME')\n",
        "})\n",
        "print(df.head(128))\n",
        "\n",
        "# Define the interval start and end\n",
        "interval_start = 2014+4/12\n",
        "interval_end = 2016+4/12\n",
        "intervention_date = df['Date'][64]\n",
        "\n",
        "# Filter the DataFrame for the desired interval\n",
        "filtered_df = df[(df['cp_time'] >= interval_start) & (df['cp_time'] < interval_end)]\n",
        "\n",
        "# Sum the probabilities for the filtered interval\n",
        "sum_probs = filtered_df['cp_occ_pr'].sum()\n",
        "print(\"Sum of changepoint probabilities over the interval:\", sum_probs)\n",
        "print(\"We have a\", sum_probs * 100, \"% chance that the change occurred between May-2014 and May-2016\")\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['Date'], df['cp_occ_pr'], label='Changepoint Occurrence Probability')\n",
        "plt.fill_between(filtered_df['Date'], filtered_df['cp_occ_pr'], color='skyblue', alpha=0.4, label=f'AUC from 05/2014 to 05/2016: {sum_probs:.2f}')\n",
        "plt.ylabel('Probability')\n",
        "plt.title('Changepoint Occurrence Probability For Intravenous PPI DDD Over Time')\n",
        "plt.axvline(x=intervention_date, color='C3', linestyle='--', label='Intervention (May 2014)')\n",
        "plt.legend()\n",
        "plt.ylim(-0.005, 0.107)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohuIeZ8eqcyA"
      },
      "outputs": [],
      "source": [
        "# Define the interval start and end\n",
        "interval_start = 2014+4/12\n",
        "interval_end = 2016+4/12\n",
        "\n",
        "\n",
        "# o.time is a NumPy array with time points\n",
        "# o.trend.cpOccPr is a NumPy array with corresponding probabilities\n",
        "\n",
        "# Find indices where time falls within the interval\n",
        "interval_indices = np.where((o.time >= interval_start) & (o.time < interval_end))\n",
        "\n",
        "# Extract the probabilities for these indices\n",
        "interval_probs = o.trend.cpOccPr[interval_indices]\n",
        "\n",
        "# Sum the probabilities\n",
        "sum_probs = np.sum(interval_probs)\n",
        "\n",
        "print(\"Sum of changepoint probabilities over the interval:\", sum_probs)\n",
        "print(\"We have a\", sum_probs*100, \"% chance that the change occured between May-2014 and May-2016\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C8fvu-gYASxb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}